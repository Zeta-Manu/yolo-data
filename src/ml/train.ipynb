{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32dc17e-97e5-4338-bf12-c6d3379ac1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Obtaining dependency information for roboflow from https://files.pythonhosted.org/packages/7b/a0/97f61b88f478b9a3cbdc9f352dd1ee65915e590cee6b32a5577c58870deb/roboflow-1.1.5-py3-none-any.whl.metadata\n",
      "  Downloading roboflow-1.1.5-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting certifi==2022.12.7 (from roboflow)\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting idna==2.10 (from roboflow)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from roboflow) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from roboflow) (1.25.2)\n",
      "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
      "  Obtaining dependency information for opencv-python-headless==4.8.0.74 from https://files.pythonhosted.org/packages/76/02/f128517f3ade4bb5f71e2afd8461dba70e3f466ce745fa1fd1fade9ad1b7/opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from roboflow) (10.0.0)\n",
      "Collecting pyparsing==2.4.7 (from roboflow)\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from roboflow) (2.8.2)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from roboflow) (1.16.0)\n",
      "Collecting supervision (from roboflow)\n",
      "  Obtaining dependency information for supervision from https://files.pythonhosted.org/packages/38/31/19d39cde7723206ecc1e054d16c792204a76ab884fefa656ea297b26af9e/supervision-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading supervision-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from roboflow) (1.26.16)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from roboflow) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from roboflow) (6.0.1)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from matplotlib->roboflow) (1.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from matplotlib->roboflow) (4.42.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from matplotlib->roboflow) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from requests->roboflow) (3.2.0)\n",
      "Collecting Pillow>=7.1.2 (from roboflow)\n",
      "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy<2.0.0,>=1.9.0 in /home/zack/Projects/datasci-test/test/lib/python3.10/site-packages (from supervision->roboflow) (1.11.2)\n",
      "Downloading roboflow-1.1.5-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading supervision-0.14.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-dotenv, pyparsing, Pillow, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 10.0.0\n",
      "    Uninstalling Pillow-10.0.0:\n",
      "      Successfully uninstalled Pillow-10.0.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.11.0\n",
      "    Uninstalling cycler-0.11.0:\n",
      "      Successfully uninstalled cycler-0.11.0\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2023.7.22\n",
      "    Uninstalling certifi-2023.7.22:\n",
      "      Successfully uninstalled certifi-2023.7.22\n",
      "Successfully installed Pillow-9.5.0 certifi-2022.12.7 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.1.5 supervision-0.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e45ad4-6485-4b03-a62b-8c9a87c2db03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.134 is required but found version=8.0.167, to fix: `pip install ultralytics==8.0.134`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in ASL-Detection-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66839/66839 [00:06<00:00, 9608.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to ASL-Detection-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5882/5882 [00:00<00:00, 24091.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"cDYF3J6tFXHdkEZBmJCj\")\n",
    "project = rf.workspace(\"manu-fd9da\").project(\"asl-detection-ib7vw\")\n",
    "dataset = project.version(1).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4cbc4c-b1eb-450e-bcd1-77969a0010b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'HOME'\n",
      "/home/zack/Projects/datasci-test/src/ml\n"
     ]
    }
   ],
   "source": [
    "%cd HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71386346-3fd5-4cb7-99d6-813894d1cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n.yaml')  # build a new model from YAML\n",
    "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
    "model = YOLO('yolov8n.yaml').load('yolov8n.pt')  # build from YAML and transfer weights\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data='/home/zack/Projects/datasci-test/src/ml/ASL-Detection-1/data.yaml', epochs=20, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ccce3b-be8c-40a6-91f1-f6f0183d13e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.167 ğŸš€ Python-3.10.12 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 4070, 11975MiB)\n",
      "YOLOv8s summary (fused): 168 layers, 11129454 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/zack/Projects/datasci-test/src/ml/ASL-Detection-1/valid/labels.cache... 245 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245/245 [00:0\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  8.95it/s]\n",
      "                   all        245        245      0.992      0.992      0.995      0.994\n",
      "                before        245         32      0.993          1      0.995      0.995\n",
      "              computer        245         20      0.989          1      0.995      0.995\n",
      "                  cool        245         26      0.989          1      0.995      0.995\n",
      "                cousin        245         27       0.99          1      0.995      0.995\n",
      "                 drink        245         20      0.984          1      0.995      0.995\n",
      "                    go        245         25          1      0.945      0.992      0.981\n",
      "                  help        245         28          1      0.976      0.995      0.995\n",
      "                 short        245         27      0.991          1      0.995      0.995\n",
      "                  thin        245         19      0.986          1      0.995      0.995\n",
      "                   who        245         21      0.995          1      0.995      0.995\n",
      "Speed: 0.5ms preprocess, 3.5ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([      0.995,       0.995,       0.995,       0.995,       0.995,     0.98116,       0.995,       0.995,       0.995,       0.995])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8m.pt')  # load an official model\n",
    "model = YOLO('runs/detect/train21/weights/best.pt')  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map    # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps   # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e55267a1-e335-4cd3-ab7e-bb859ac3064a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    WARNING âš ï¸ stream/video/webcam/dir predict source will accumulate results in RAM unless `stream=True` is passed,\n",
      "    causing potential out-of-memory errors for large sources or long-running streams/videos.\n",
      "\n",
      "    Example:\n",
      "        results = model(source=..., stream=True)  # generator of Results objects\n",
      "        for r in results:\n",
      "            boxes = r.boxes  # Boxes object for bbox outputs\n",
      "            masks = r.masks  # Masks object for segment masks outputs\n",
      "            probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (1/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 15.6ms\n",
      "video 1/1 (2/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 5.9ms\n",
      "video 1/1 (3/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.5ms\n",
      "video 1/1 (4/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.4ms\n",
      "video 1/1 (5/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.4ms\n",
      "video 1/1 (6/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.7ms\n",
      "video 1/1 (7/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.5ms\n",
      "video 1/1 (8/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 7.0ms\n",
      "video 1/1 (9/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.5ms\n",
      "video 1/1 (10/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 7.4ms\n",
      "video 1/1 (11/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.6ms\n",
      "video 1/1 (12/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.7ms\n",
      "video 1/1 (13/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.7ms\n",
      "video 1/1 (14/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.4ms\n",
      "video 1/1 (15/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.4ms\n",
      "video 1/1 (16/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.9ms\n",
      "video 1/1 (17/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.5ms\n",
      "video 1/1 (18/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 5.9ms\n",
      "video 1/1 (19/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.5ms\n",
      "video 1/1 (20/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.4ms\n",
      "video 1/1 (21/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.4ms\n",
      "video 1/1 (22/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.7ms\n",
      "video 1/1 (23/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.5ms\n",
      "video 1/1 (24/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 5.9ms\n",
      "video 1/1 (25/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.5ms\n",
      "video 1/1 (26/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.0ms\n",
      "video 1/1 (27/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.0ms\n",
      "video 1/1 (28/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (29/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (30/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (31/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (32/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (33/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (34/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (35/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (36/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (37/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (38/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (39/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (40/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.3ms\n",
      "video 1/1 (41/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.6ms\n",
      "video 1/1 (42/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (43/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.6ms\n",
      "video 1/1 (44/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (45/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (46/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (47/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.3ms\n",
      "video 1/1 (48/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (49/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (50/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (51/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (52/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (53/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.2ms\n",
      "video 1/1 (54/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 5.0ms\n",
      "video 1/1 (55/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (56/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (57/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (58/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (59/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (60/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.3ms\n",
      "video 1/1 (61/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (62/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.3ms\n",
      "video 1/1 (63/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.2ms\n",
      "video 1/1 (64/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (65/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (66/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (67/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 6.4ms\n",
      "video 1/1 (68/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (69/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 6.4ms\n",
      "video 1/1 (70/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.7ms\n",
      "video 1/1 (71/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (72/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (73/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (74/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 5.0ms\n",
      "video 1/1 (75/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.2ms\n",
      "video 1/1 (76/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 6.4ms\n",
      "video 1/1 (77/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.2ms\n",
      "video 1/1 (78/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (79/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (80/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (81/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.3ms\n",
      "video 1/1 (82/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.2ms\n",
      "video 1/1 (83/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (84/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (85/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (86/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.4ms\n",
      "video 1/1 (87/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (88/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.4ms\n",
      "video 1/1 (89/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.5ms\n",
      "video 1/1 (90/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (91/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (92/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 1 cousin, 4.1ms\n",
      "video 1/1 (93/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (94/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (95/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (96/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 6.9ms\n",
      "video 1/1 (97/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.2ms\n",
      "video 1/1 (98/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (99/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (100/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 6.5ms\n",
      "video 1/1 (101/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (102/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.3ms\n",
      "video 1/1 (103/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.1ms\n",
      "video 1/1 (104/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 6.4ms\n",
      "video 1/1 (105/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.6ms\n",
      "video 1/1 (106/106) /home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4: 480x640 (no detections), 4.3ms\n",
      "Speed: 0.9ms preprocess, 4.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8n model\n",
    "model = YOLO('runs/detect/train21/weights/best.pt')\n",
    "\n",
    "# Define source as YouTube video URL\n",
    "source = '/home/zack/Projects/datasci-test/data/transform/videos/cousin/13630.mp4'\n",
    "\n",
    "# Run inference on the source\n",
    "results = model(source, stream=False)  # generator of Results objects\n",
    "\n",
    "# Process results generator\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bbox outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be90bc1f-fb64-489c-966e-dfac84490281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for r in results:\n",
    "    print(r.probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2072d611-601e-46c1-99b8-f395b0a6287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 10.9ms\n",
      "Speed: 1.9ms preprocess, 10.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) /io/opencv/modules/highgui/src/window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m annotated_frame \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Display the annotated frame\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYOLOv8 Inference\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotated_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Break the loop if 'q' is pressed\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/highgui/src/window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('runs/detect/train17/weights/best.pt')\n",
    "\n",
    "# Open the video file\n",
    "video_path = '/home/zack/Projects/datasci-test/data/transform/videos/hello/27172.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312a875-6d3a-4ce2-bf47-44d7ed4ed24e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
